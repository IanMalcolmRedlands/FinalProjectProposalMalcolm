{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10170d46-20cf-4b25-958e-42e05b826605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from itables import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dfa41b9-bff4-4c7d-aa26-99a414ec5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdir = 'RawClimDiv'\n",
    "climdir = 'ClimDivData'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8b412-27d5-4322-b576-91e5493edb62",
   "metadata": {},
   "source": [
    "#### Add Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43a374f-bb59-40fb-b8aa-fa3fccc10422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawClimDiv/climdiv_pcpn_cty.txt\n",
      "RawClimDiv/climdiv_tmin_st.txt\n",
      "RawClimDiv/climdiv_tmin_cty.txt\n",
      "RawClimDiv/climdiv_tavg_st.txt\n",
      "RawClimDiv/climdiv_tmax_st.txt\n",
      "RawClimDiv/climdiv_tmax_cty.txt\n",
      "RawClimDiv/climdiv_pcpn_st.txt\n",
      "RawClimDiv/climdiv_tavg_cty.txt\n"
     ]
    }
   ],
   "source": [
    "def add_headers(rawdi, outdir):\n",
    "    for _,_,files in os.walk(rawdir):\n",
    "        break\n",
    "    \n",
    "    for filename in files:\n",
    "        if filename.find('readme') < 0:\n",
    "            print(os.path.join(rawdir, filename))\n",
    "            with open(os.path.join(rawdir, filename), 'r') as f, open(os.path.join(outdir, filename), 'w') as o:\n",
    "                content = f.read()\n",
    "                line='Code  Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec'\n",
    "                o.write(line + '\\n' + content)\n",
    "                \n",
    "add_headers(rawdir, climdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b26a209-b084-4875-8340-9bec3fe210ef",
   "metadata": {},
   "source": [
    "#### Split Code Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db1cd91a-ab0c-4a03-b21a-a7a5bdb29317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_255272/1332691058.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n",
      "/tmp/ipykernel_255272/1332691058.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n",
      "/tmp/ipykernel_255272/1332691058.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n",
      "/tmp/ipykernel_255272/1332691058.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n"
     ]
    }
   ],
   "source": [
    "#county stuff\n",
    "for _,_,files in os.walk(climdir):\n",
    "    break\n",
    "\n",
    "dfs_dict = {}\n",
    "for filename in files:\n",
    "    if not filename.endswith('cty.txt'):\n",
    "        continue\n",
    "            \n",
    "    fpath = os.path.join(climdir, filename)\n",
    "    dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n",
    "\n",
    "    dict['StateId'] = dict['Code'].str[0:2]\n",
    "    dict['CountyFips'] = dict['Code'].str[2:5]\n",
    "    dict['DataType'] = dict['Code'].str[5:7]\n",
    "    dict['Year'] = dict['Code'].str[7:12]\n",
    "\n",
    "    cols = list(dict.columns)\n",
    "    cols.remove('Year')\n",
    "    cols.insert(0, 'Year')\n",
    "    cols.remove('CountyFips')\n",
    "    cols.insert(0, 'CountyFips')\n",
    "    cols.remove('StateId')\n",
    "    cols.insert(0, 'StateId')\n",
    "    cols.remove('DataType')\n",
    "    cols.insert(0, 'DataType')\n",
    "    cols.remove('Code')\n",
    "    dict = dict[cols]\n",
    "\n",
    "    outpath = os.path.join(climdir, filename.split('.')[0] + '_clean.csv')\n",
    "    dict.to_csv(outpath, index=False)\n",
    "\n",
    "    os.remove(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7c7aaa-a3cb-461d-94b5-36d97c003744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_255272/3792708255.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n",
      "/tmp/ipykernel_255272/3792708255.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n",
      "/tmp/ipykernel_255272/3792708255.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n",
      "/tmp/ipykernel_255272/3792708255.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n"
     ]
    }
   ],
   "source": [
    "#state stuff\n",
    "for _,_,files in os.walk(climdir):\n",
    "    break\n",
    "\n",
    "dfs_dict = {}\n",
    "for filename in files:\n",
    "    if not filename.endswith('st.txt'):\n",
    "        continue\n",
    "            \n",
    "    fpath = os.path.join(climdir, filename)\n",
    "    dict = pd.read_csv(fpath, sep=' +', dtype={'Code': 'str'})\n",
    "\n",
    "    dict['StateId'] = dict['Code'].str[0:3]\n",
    "    dict['Division'] = dict['Code'].str[3:4]\n",
    "    dict['DataType'] = dict['Code'].str[4:6]\n",
    "    dict['Year'] = dict['Code'].str[6:10]\n",
    "\n",
    "    cols = list(dict.columns)\n",
    "    cols.remove('Year')\n",
    "    cols.insert(0, 'Year')\n",
    "    cols.remove('Division')\n",
    "    cols.insert(0, 'Division')\n",
    "    cols.remove('StateId')\n",
    "    cols.insert(0, 'StateId')\n",
    "    cols.remove('DataType')\n",
    "    cols.insert(0, 'DataType')\n",
    "    cols.remove('Code')\n",
    "    dict = dict[cols]\n",
    "\n",
    "    outpath = os.path.join(climdir, filename.split('.')[0] + '_clean.csv')\n",
    "    dict.to_csv(outpath, index=False)\n",
    "\n",
    "    os.remove(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fdbaa9-08a8-4b64-987c-dee3e7b759f7",
   "metadata": {},
   "source": [
    "#### Trim to Desired States and Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46a41a08-0adf-4781-9106-debda59dea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,_,fnames in os.walk(climdir):\n",
    "    break\n",
    "\n",
    "fipspath = os.path.join(climdir, 'StateCountyCodes.csv')\n",
    "fips_df = pd.read_csv(fipspath)\n",
    "\n",
    "state_codes = [4,30] #CA and NY\n",
    "for fname in fnames:\n",
    "    if not fname.endswith('_clean.csv'):\n",
    "        continue\n",
    "        \n",
    "    fpath = os.path.join(climdir, fname)\n",
    "    \n",
    "    dict = pd.read_csv(fpath)\n",
    "\n",
    "    mask = (dict['StateId'].isin(state_codes)) & (dict['Year']>=1980)\n",
    "    dict = dict[mask]\n",
    "\n",
    "    #touchup\n",
    "    if fname.find('cty') > -1:\n",
    "        dict = pd.merge(dict, fips_df[['ClimDiv State Id', 'County Name', 'FIPS County']],\n",
    "                        how='left',\n",
    "                        left_on=['StateId', 'CountyFips'],\n",
    "                        right_on=['ClimDiv State Id', 'FIPS County'])\n",
    "        dict['County'] = dict['County Name']\n",
    "\n",
    "    dict['State'] = dict['StateId'].replace({4:'CA', 30:'NY'})\n",
    "\n",
    "    removals = ['StateId', 'County Name', 'CountyFips', 'FIPS County', 'ClimDiv State Id', 'Division', 'State']\n",
    "    cols = list(dict.columns)\n",
    "    for col in removals:\n",
    "        if col in cols:\n",
    "            cols.remove(col)\n",
    "        \n",
    "    cols.insert(1, 'State')\n",
    "    if 'County' in cols:\n",
    "        cols.remove('County')\n",
    "        cols.insert(2, 'County')\n",
    "\n",
    "    dict = dict[cols]\n",
    "    \n",
    "    outpath = os.path.join(climdir, fname.split('.')[0] + '_trim.csv')\n",
    "    dict.to_csv(outpath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89869c-db12-423a-a9b3-106a7d8c374b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Aside: Standardizing FIPS Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df3743ca-cb5d-4937-9c97-956a610a621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_fips(fpath):\n",
    "    remap_dict = states_dict = {\n",
    "            \"Alabama\": 1,\n",
    "            \"Arizona\": 2,\n",
    "            \"Arkansas\": 3,\n",
    "            \"California\": 4,\n",
    "            \"Colorado\": 5,\n",
    "            \"Connecticut\": 6,\n",
    "            \"Delaware\": 7,\n",
    "            \"Florida\": 8,\n",
    "            \"Georgia\": 9,\n",
    "            \"Idaho\": 10,\n",
    "            \"Illinois\": 11,\n",
    "            \"Indiana\": 12,\n",
    "            \"Iowa\": 13,\n",
    "            \"Kansas\": 14,\n",
    "            \"Kentucky\": 15,\n",
    "            \"Louisiana\": 16,\n",
    "            \"Maine\": 17,\n",
    "            \"Maryland\": 18,\n",
    "            \"Massachusetts\": 19,\n",
    "            \"Michigan\": 20,\n",
    "            \"Minnesota\": 21,\n",
    "            \"Mississippi\": 22,\n",
    "            \"Missouri\": 23,\n",
    "            \"Montana\": 24,\n",
    "            \"Nebraska\": 25,\n",
    "            \"Nevada\": 26,\n",
    "            \"New Hampshire\": 27,\n",
    "            \"New Jersey\": 28,\n",
    "            \"New Mexico\": 29,\n",
    "            \"New York\": 30,\n",
    "            \"North Carolina\": 31,\n",
    "            \"North Dakota\": 32,\n",
    "            \"Ohio\": 33,\n",
    "            \"Oklahoma\": 34,\n",
    "            \"Oregon\": 35,\n",
    "            \"Pennsylvania\": 36,\n",
    "            \"Rhode Island\": 37,\n",
    "            \"South Carolina\": 38,\n",
    "            \"South Dakota\": 39,\n",
    "            \"Tennessee\": 40,\n",
    "            \"Texas\": 41,\n",
    "            \"Utah\": 42,\n",
    "            \"Vermont\": 43,\n",
    "            \"Virginia\": 44,\n",
    "            \"Washington\": 45,\n",
    "            \"West Virginia\": 46,\n",
    "            \"Wisconsin\": 47,\n",
    "            \"Wyoming\": 48,\n",
    "            \"Alaska\": 50\n",
    "        }\n",
    "\n",
    "    fips_df = pd.read_csv(fpath)\n",
    "    fips_df['ClimDiv State Id'] = fips_df['State'].map(remap_dict)\n",
    "\n",
    "    fips_df = fips_df[~fips_df['ClimDiv State Id'].isna()]\n",
    "    fips_df['ClimDiv State Id'] = fips_df['ClimDiv State Id'].astype(int)\n",
    "\n",
    "    cols = list(fips_df.columns)\n",
    "    cols.remove('FIPS State')\n",
    "    cols.remove('ClimDiv State Id')\n",
    "    cols.insert(1, 'ClimDiv State Id')\n",
    "    fips_df = fips_df[cols]\n",
    "\n",
    "    fips_df.to_csv(fpath.split('.')[0]+'_new.csv', index=False)\n",
    "\n",
    "#standardize_fips('ClimDivData/UsFips_ONLY_FOR_COUNTY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b916a49-b460-4168-8ec7-abcd56a0de1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
